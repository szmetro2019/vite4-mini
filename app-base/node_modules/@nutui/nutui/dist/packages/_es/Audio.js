/*!
* @nutui/nutui v3.3.8 Mon Jun 12 2023 11:24:18 GMT+0800 (中国标准时间)
* (c) 2022 @jdf2e.
* Released under the MIT License.
*/
import { ref, reactive, onMounted, watch, provide, toRefs, resolveComponent, openBlock, createElementBlock, createElementVNode, toDisplayString, createVNode, withCtx, createCommentVNode, normalizeClass, createBlock, renderSlot } from "vue";
import { c as createComponent } from "./component.js";
import { _ as _export_sfc } from "./plugin-vue_export-helper.js";
import "../locale/lang";
const { componentName, create } = createComponent("audio");
const _sfc_main = create({
  props: {
    url: {
      type: String,
      default: ""
    },
    muted: {
      type: Boolean,
      default: false
    },
    autoplay: {
      type: Boolean,
      default: false
    },
    loop: {
      type: Boolean,
      default: false
    },
    preload: {
      type: String,
      default: "auto"
    },
    second: {
      type: Number,
      default: 0
    },
    type: {
      type: String,
      default: "progress"
    }
  },
  components: {},
  emits: ["fastBack", "play", "forward", "ended", "changeProgress", "mute", "can-play"],
  setup(props, { emit }) {
    const audioRef = ref(null);
    const audioData = reactive({
      currentTime: 0,
      currentDuration: "00:00:00",
      percent: 0,
      duration: "00:00:00",
      second: 0,
      hanMuted: props.muted,
      playing: props.autoplay,
      handPlaying: false
    });
    onMounted(() => {
      var arr = ["webkitVisibilityState", "visibilitychange"];
      try {
        for (let i = 0; i < arr.length; i++) {
          document.addEventListener(arr[i], () => {
            if (document.hidden) {
              audioRef.value.pause();
            } else {
              if (audioData.playing) {
                setTimeout(() => {
                  audioRef.value.play();
                }, 200);
              }
            }
          });
        }
      } catch (e) {
        console.log(e.message);
      }
    });
    const onCanplay = (e) => {
      const audioR = audioRef.value;
      if (props.autoplay) {
        if (audioR && audioR.paused) {
          audioR.play();
        }
      }
      audioData.second = audioR.duration;
      audioData.duration = formatSeconds(audioR.duration);
      emit("can-play", e);
    };
    const onTimeupdate = (e) => {
      audioData.currentTime = parseInt(e.target.currentTime);
    };
    const fastBack = () => {
      if (audioData.currentTime > 0) {
        audioData.currentTime--;
      }
      audioRef.value.currentTime = audioData.currentTime;
      emit("fastBack", audioData.currentTime);
    };
    const changeStatus = () => {
      const audioR = audioRef.value;
      if (audioData.playing) {
        audioR.pause();
        audioData.handPlaying = false;
      } else {
        audioR.play();
        audioData.handPlaying = true;
      }
      audioData.playing = !audioData.playing;
      emit("play", audioData.playing);
    };
    const forward = () => {
      audioData.currentTime++;
      audioRef.value.currentTime = audioData.currentTime;
      emit("forward", audioData.currentTime);
    };
    const handle = (val) => {
      audioData.currentDuration = formatSeconds(val);
      audioData.percent = val / audioData.second * 100;
    };
    const audioEnd = () => {
      audioData.playing = false;
      emit("ended");
    };
    const progressChange = (val) => {
      const ar = audioRef.value;
      ar.currentTime = audioData.second * val / 100;
      emit("changeProgress", ar.currentTime);
    };
    const handleMute = () => {
      audioData.hanMuted = !audioData.hanMuted;
      emit("mute", audioData.hanMuted);
    };
    const formatSeconds = (value) => {
      if (!value) {
        return "00:00:00";
      }
      let time = parseInt(value);
      let hours = Math.floor(time / 3600);
      let minutes = Math.floor((time - hours * 3600) / 60);
      let seconds = time - hours * 3600 - minutes * 60;
      let result = "";
      result += ("0" + hours.toString()).slice(-2) + ":";
      result += ("0" + minutes.toString()).slice(-2) + ":";
      result += ("0" + seconds.toString()).slice(-2);
      return result;
    };
    watch(
      () => audioData.currentTime,
      (value) => {
        handle(value);
      }
    );
    provide("audioParent", {
      children: [],
      props,
      audioData,
      handleMute,
      forward,
      fastBack,
      changeStatus
    });
    return {
      ...toRefs(props),
      ...toRefs(audioData),
      audioRef,
      fastBack,
      forward,
      changeStatus,
      progressChange,
      audioEnd,
      onTimeupdate,
      handleMute,
      onCanplay
    };
  }
});
const _hoisted_1 = { class: "nut-audio" };
const _hoisted_2 = {
  key: 0,
  class: "progress-wrapper"
};
const _hoisted_3 = { class: "time" };
const _hoisted_4 = { class: "progress-bar-wrapper" };
const _hoisted_5 = /* @__PURE__ */ createElementVNode("div", { class: "custom-button" }, null, -1);
const _hoisted_6 = { class: "time" };
const _hoisted_7 = {
  key: 1,
  class: "nut-audio-icon"
};
const _hoisted_8 = ["controls", "src", "preload", "autoplay", "loop", "muted"];
function _sfc_render(_ctx, _cache, $props, $setup, $data, $options) {
  const _component_nut_range = resolveComponent("nut-range");
  const _component_nut_icon = resolveComponent("nut-icon");
  return openBlock(), createElementBlock("div", _hoisted_1, [
    _ctx.type == "progress" ? (openBlock(), createElementBlock("div", _hoisted_2, [
      createElementVNode("div", _hoisted_3, toDisplayString(_ctx.currentDuration), 1),
      createElementVNode("div", _hoisted_4, [
        createVNode(_component_nut_range, {
          modelValue: _ctx.percent,
          "onUpdate:modelValue": _cache[0] || (_cache[0] = ($event) => _ctx.percent = $event),
          "hidden-range": "",
          onChange: _ctx.progressChange,
          "inactive-color": "#cccccc",
          "active-color": "#fa2c19"
        }, {
          button: withCtx(() => [
            _hoisted_5
          ]),
          _: 1
        }, 8, ["modelValue", "onChange"])
      ]),
      createElementVNode("div", _hoisted_6, toDisplayString(_ctx.duration), 1)
    ])) : createCommentVNode("", true),
    _ctx.type == "icon" ? (openBlock(), createElementBlock("div", _hoisted_7, [
      createElementVNode("div", {
        class: normalizeClass(["nut-audio-icon-box", _ctx.playing ? "nut-audio-icon-play" : "nut-audio-icon-stop"]),
        onClick: _cache[1] || (_cache[1] = (...args) => _ctx.changeStatus && _ctx.changeStatus(...args))
      }, [
        _ctx.playing ? (openBlock(), createBlock(_component_nut_icon, {
          key: 0,
          name: "service",
          class: "nut-icon-am-rotate nut-icon-am-infinite"
        })) : createCommentVNode("", true),
        !_ctx.playing ? (openBlock(), createBlock(_component_nut_icon, {
          key: 1,
          name: "service"
        })) : createCommentVNode("", true)
      ], 2)
    ])) : createCommentVNode("", true),
    _ctx.type == "none" ? (openBlock(), createElementBlock("div", {
      key: 2,
      onClick: _cache[2] || (_cache[2] = (...args) => _ctx.changeStatus && _ctx.changeStatus(...args))
    }, [
      renderSlot(_ctx.$slots, "default")
    ])) : createCommentVNode("", true),
    _ctx.type != "none" ? renderSlot(_ctx.$slots, "default", { key: 3 }) : createCommentVNode("", true),
    createElementVNode("audio", {
      class: "audioMain",
      controls: _ctx.type == "controls",
      ref: "audioRef",
      src: _ctx.url,
      preload: _ctx.preload,
      autoplay: _ctx.autoplay,
      loop: _ctx.loop,
      onTimeupdate: _cache[3] || (_cache[3] = (...args) => _ctx.onTimeupdate && _ctx.onTimeupdate(...args)),
      onCanplay: _cache[4] || (_cache[4] = (...args) => _ctx.onCanplay && _ctx.onCanplay(...args)),
      onEnded: _cache[5] || (_cache[5] = (...args) => _ctx.audioEnd && _ctx.audioEnd(...args)),
      muted: _ctx.hanMuted
    }, null, 40, _hoisted_8)
  ]);
}
var index = /* @__PURE__ */ _export_sfc(_sfc_main, [["render", _sfc_render]]);
export { index as default };
